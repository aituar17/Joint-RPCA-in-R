options(warn = -1)
#load user-defined functions
source("../R/dependencies.R")
source("../R/jointRPCA.R")
source("../R/jointRPCAmae.R")
source("../R/jointOptspaceHelper.R")
source("../R/jointOptspaceSolve.R")
source("../R/optspaceHelper.R")
source("../R/transformHelper.R")
source("../R/transform.R")
source("../R/maskValueOnly.R")
source("../R/rpcaTableProcessing.R")
source("../R/jointRPCAutils.R")

suppressPackageStartupMessages({
library(mia)
library(ggplot2)
})

#extract sample and feature scores
samples_df <- as.data.frame(result$ord.res$samples)
samples_df$Label <- rownames(samples_df)

#get test/train labels from metadata
sample_metadata <- as.data.frame(SummarizedExperiment::colData(HintikkaXOData))
sample_metadata$Label <- rownames(sample_metadata)

#manually tag samples as train/test
sample_metadata$Set <- c(rep("train", 7), rep("test", nrow(sample_metadata) - 7))

#merge with ordination scores
samples_df <- merge(samples_df, sample_metadata[, c("Label", "Set")],
                    by = "Label", all.x = TRUE)

#feature scores
features_df <- as.data.frame(result$ord.res$features)
features_df$Label <- rownames(features_df)

#sample ordination plot
ggplot(samples_df, aes(x = PC1, y = PC2, color = Set)) +
  geom_point(size = 3) +
  geom_text(aes(label = Label), vjust = -1.2) +
  theme_minimal() +
  scale_color_manual(values = c("train" = "steelblue", "test" = "tomato")) +
  labs(title = "Joint RPCA Ordination on HintikkaXOData", x = "PC1", y = "PC2")

# Feature Importance Analysis

#rank features by contribution
loadings <- result$ord.res$features

ranked_features <- lapply(colnames(loadings), function(pc) {
  df <- data.frame(
    Feature = rownames(loadings),
    Loading = loadings[, pc],
    AbsLoading = abs(loadings[, pc])
  )
  df <- df[order(-df$AbsLoading), ]
  rownames(df) <- NULL
  df
})
names(ranked_features) <- colnames(loadings)

#view top features
head(ranked_features$PC1, 5)
head(ranked_features$PC2, 5)

# Visualize Top Features Driving PC1

top_PC1 <- head(ranked_features$PC1, 10)

ggplot(top_PC1, aes(x = reorder(Feature, AbsLoading), y = AbsLoading)) +
  geom_col(fill = "darkslateblue") +
  coord_flip() +
  labs(title = "Top Features Driving PC1 in HintikkaXOData",
       x = NULL, y = "Absolute Loading")


# Compute and Visualize Covariance Matrix of Feature Loadings

# Covariance matrix of joint feature loadings

# Extract joint feature loadings
feature_loadings <- metadata(HintikkaXOData[["microbiota"]])$jointRPCA_feature_loadings

# Subset the numeric columns (PC axes)
loadings_matrix <- as.matrix(feature_loadings[, c("PC1", "PC2")])

# Compute a feature-feature covariance matrix
pairwise_cov <- tcrossprod(loadings_matrix)

# Melt the covariance matrix to long format
cov_long <- melt(pairwise_cov)
names(cov_long) <- c("Feature1", "Feature2", "Covariance")

# Plot covariance heatmap
ggplot(cov_long, aes(x = Feature1, y = Feature2, fill = Covariance)) +
  geom_tile() +
  scale_fill_gradient2(low = "darkred", high = "darkgreen", mid = "white",
                       midpoint = 0, limit = c(min(cov_long$Covariance), max(cov_long$Covariance)),
                       name = "Covariance") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Covariance Matrix of RPCA Feature Loadings",
       x = "Feature", y = "Feature")




mofa_object <- create_mofa(mofa_data)
data_opts <- get_default_data_options(mofa_object)
model_opts <- get_default_model_options(mofa_object)
train_opts <- get_default_training_options(mofa_object)
train_opts$maxiter <- 1000
mofa_prep <- prepare_mofa(
  object = mofa_object,
  data_options = data_opts,
  model_options = model_opts,
  training_options = train_opts
)
mofa_trained <- run_mofa(mofa_prep)
factors_list <- get_factors(mofa_trained, factors = "all", as.data.frame = FALSE)
features_mofa <- factors_list[[1]]
labels_mofa <- labels[match(rownames(features_mofa), names(labels))]

#prepare randomly generated features as an input feature set
set.seed(42)
features_random <- matrix(runif(length(labels) * 10), ncol = 10)

#create a classification function (Random Forest)
evaluate_model_cv <- function(features, labels, folds = 5) {
  labels <- as.factor(labels)
  folds_idx <- createFolds(labels, k = folds, list = TRUE, returnTrain = FALSE)
  
  accs <- c()
  aucs <- c()
  
  for (i in seq_along(folds_idx)) {
    test_idx <- folds_idx[[i]]
    train_idx <- setdiff(seq_along(labels), test_idx)
    
    rf_model <- randomForest(x = features[train_idx, ], y = labels[train_idx], ntree = 500)
    pred_class <- predict(rf_model, features[test_idx, ])
    acc <- mean(pred_class == labels[test_idx])
    
    pred_probs <- predict(rf_model, features[test_idx, ], type = "prob")
    auc <- multiclass.roc(labels[test_idx], pred_probs)$auc
    
    accs <- c(accs, acc)
    aucs <- c(aucs, auc)
  }
  
  return(list(accuracy = mean(accs), auc = mean(aucs)))
}

#evaluate all methods
res_joint <- evaluate_model_cv(features_jointRPCA, labels)
res_rclr <- evaluate_model_cv(features_rclr_concat, labels)
res_pca <- evaluate_model_cv(features_pca_concat, labels)
res_rpca <- evaluate_model_cv(features_rpca_concat, labels)
res_mofa <- evaluate_model_cv(features_mofa, labels_mofa)
res_random <- evaluate_model_cv(features_random, labels)

#create and print a summary table
results_df <- data.frame(
  Method = c("Joint-RPCA", "Raw rCLR-Transformed Features", "Per-layer PCA", "Per-layer RPCA", "MOFA+", "Random"),
  Accuracy = c(res_joint$accuracy, res_rclr$accuracy, res_pca$accuracy, res_rpca$accuracy, res_mofa$accuracy, res_random$accuracy),
  AUC = c(res_joint$auc, res_rclr$auc, res_pca$auc, res_rpca$auc, res_mofa$auc, res_random$auc)
)

print(results_df)
