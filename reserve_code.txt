options(warn = -1)
#load user-defined functions
source("../R/dependencies.R")
source("../R/jointRPCA.R")
source("../R/jointRPCAmae.R")
source("../R/jointOptspaceHelper.R")
source("../R/jointOptspaceSolve.R")
source("../R/optspaceHelper.R")
source("../R/transformHelper.R")
source("../R/transform.R")
source("../R/maskValueOnly.R")
source("../R/rpcaTableProcessing.R")
source("../R/jointRPCAutils.R")

suppressPackageStartupMessages({
library(mia)
library(ggplot2)
})

#extract sample and feature scores
samples_df <- as.data.frame(result$ord.res$samples)
samples_df$Label <- rownames(samples_df)

#get test/train labels from metadata
sample_metadata <- as.data.frame(SummarizedExperiment::colData(HintikkaXOData))
sample_metadata$Label <- rownames(sample_metadata)

#manually tag samples as train/test
sample_metadata$Set <- c(rep("train", 7), rep("test", nrow(sample_metadata) - 7))

#merge with ordination scores
samples_df <- merge(samples_df, sample_metadata[, c("Label", "Set")],
                    by = "Label", all.x = TRUE)

#feature scores
features_df <- as.data.frame(result$ord.res$features)
features_df$Label <- rownames(features_df)

#sample ordination plot
ggplot(samples_df, aes(x = PC1, y = PC2, color = Set)) +
  geom_point(size = 3) +
  geom_text(aes(label = Label), vjust = -1.2) +
  theme_minimal() +
  scale_color_manual(values = c("train" = "steelblue", "test" = "tomato")) +
  labs(title = "Joint RPCA Ordination on HintikkaXOData", x = "PC1", y = "PC2")

# Feature Importance Analysis

#rank features by contribution
loadings <- result$ord.res$features

ranked_features <- lapply(colnames(loadings), function(pc) {
  df <- data.frame(
    Feature = rownames(loadings),
    Loading = loadings[, pc],
    AbsLoading = abs(loadings[, pc])
  )
  df <- df[order(-df$AbsLoading), ]
  rownames(df) <- NULL
  df
})
names(ranked_features) <- colnames(loadings)

#view top features
head(ranked_features$PC1, 5)
head(ranked_features$PC2, 5)

# Visualize Top Features Driving PC1

top_PC1 <- head(ranked_features$PC1, 10)

ggplot(top_PC1, aes(x = reorder(Feature, AbsLoading), y = AbsLoading)) +
  geom_col(fill = "darkslateblue") +
  coord_flip() +
  labs(title = "Top Features Driving PC1 in HintikkaXOData",
       x = NULL, y = "Absolute Loading")


# Compute and Visualize Covariance Matrix of Feature Loadings

# Covariance matrix of joint feature loadings

# Extract joint feature loadings
feature_loadings <- metadata(HintikkaXOData[["microbiota"]])$jointRPCA_feature_loadings

# Subset the numeric columns (PC axes)
loadings_matrix <- as.matrix(feature_loadings[, c("PC1", "PC2")])

# Compute a feature-feature covariance matrix
pairwise_cov <- tcrossprod(loadings_matrix)

# Melt the covariance matrix to long format
cov_long <- melt(pairwise_cov)
names(cov_long) <- c("Feature1", "Feature2", "Covariance")

# Plot covariance heatmap
ggplot(cov_long, aes(x = Feature1, y = Feature2, fill = Covariance)) +
  geom_tile() +
  scale_fill_gradient2(low = "darkred", high = "darkgreen", mid = "white",
                       midpoint = 0, limit = c(min(cov_long$Covariance), max(cov_long$Covariance)),
                       name = "Covariance") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Covariance Matrix of RPCA Feature Loadings",
       x = "Feature", y = "Feature")



mofa_object <- create_mofa(mofa_data)
data_opts <- get_default_data_options(mofa_object)
model_opts <- get_default_model_options(mofa_object)
train_opts <- get_default_training_options(mofa_object)
train_opts$maxiter <- 1000
mofa_prep <- prepare_mofa(
  object = mofa_object,
  data_options = data_opts,
  model_options = model_opts,
  training_options = train_opts
)
mofa_trained <- run_mofa(mofa_prep)
factors_list <- get_factors(mofa_trained, factors = "all", as.data.frame = FALSE)
features_mofa <- factors_list[[1]]
labels_mofa <- labels[match(rownames(features_mofa), names(labels))]

#prepare randomly generated features as an input feature set
set.seed(42)
features_random <- matrix(runif(length(labels) * 10), ncol = 10)

#create a classification function (Random Forest)
evaluate_model_cv <- function(features, labels, folds = 5) {
  labels <- as.factor(labels)
  folds_idx <- createFolds(labels, k = folds, list = TRUE, returnTrain = FALSE)
  
  accs <- c()
  aucs <- c()
  
  for (i in seq_along(folds_idx)) {
    test_idx <- folds_idx[[i]]
    train_idx <- setdiff(seq_along(labels), test_idx)
    
    rf_model <- randomForest(x = features[train_idx, ], y = labels[train_idx], ntree = 500)
    pred_class <- predict(rf_model, features[test_idx, ])
    acc <- mean(pred_class == labels[test_idx])
    
    pred_probs <- predict(rf_model, features[test_idx, ], type = "prob")
    auc <- multiclass.roc(labels[test_idx], pred_probs)$auc
    
    accs <- c(accs, acc)
    aucs <- c(aucs, auc)
  }
  
  return(list(accuracy = mean(accs), auc = mean(aucs)))
}

#evaluate all methods
res_joint <- evaluate_model_cv(features_jointRPCA, labels)
res_rclr <- evaluate_model_cv(features_rclr_concat, labels)
res_pca <- evaluate_model_cv(features_pca_concat, labels)
res_rpca <- evaluate_model_cv(features_rpca_concat, labels)
res_mofa <- evaluate_model_cv(features_mofa, labels_mofa)
res_random <- evaluate_model_cv(features_random, labels)

#create and print a summary table
results_df <- data.frame(
  Method = c("Joint-RPCA", "Raw rCLR-Transformed Features", "Per-layer PCA", "Per-layer RPCA", "MOFA+", "Random"),
  Accuracy = c(res_joint$accuracy, res_rclr$accuracy, res_pca$accuracy, res_rpca$accuracy, res_mofa$accuracy, res_random$accuracy),
  AUC = c(res_joint$auc, res_rclr$auc, res_pca$auc, res_rpca$auc, res_mofa$auc, res_random$auc)
)

print(results_df)






#create label vector
labels <- colData(HintikkaXOData)$Diet

#prepare different input feature sets

#prepare Joint-RPCA sample scores as an input feature set
features_jointRPCA <- result$ord.res$samples

#prepare RPCA sample scores per omic, then concatenated, as an input feature set
features_rpca_concat <- do.call(cbind, dataset_specific_scores)

#prepare single-layer RPCA sample scores (layer 1) as an input feature set
features_layer1 <- dataset_specific_scores[[1]]

#prepare randomly generated features as an input feature set
set.seed(42)
features_random <- matrix(runif(length(labels) * 10), ncol = 10)

#create a classification function (Random Forest)
evaluate_model_cv <- function(features, labels, folds = 5) {
  labels <- as.factor(labels)
  folds_idx <- createFolds(labels, k = folds, list = TRUE, returnTrain = FALSE)
  
  accs <- c()
  aucs <- c()
  
  for (i in seq_along(folds_idx)) {
    test_idx <- folds_idx[[i]]
    train_idx <- setdiff(seq_along(labels), test_idx)
    
    rf_model <- randomForest(x = features[train_idx, ], y = labels[train_idx], ntree = 500)
    pred_class <- predict(rf_model, features[test_idx, ])
    acc <- mean(pred_class == labels[test_idx])
    
    pred_probs <- predict(rf_model, features[test_idx, ], type = "prob")
    auc <- multiclass.roc(labels[test_idx], pred_probs)$auc
    
    accs <- c(accs, acc)
    aucs <- c(aucs, auc)
  }
  
  return(list(accuracy = mean(accs), auc = mean(aucs)))
}

#evaluate all methods
res_joint <- evaluate_model_cv(features_jointRPCA, labels)
res_rpca <- evaluate_model_cv(features_rpca_concat, labels)
res_layer1 <- evaluate_model_cv(features_layer1, labels)
res_random <- evaluate_model_cv(features_random, labels)

#create and print a summary table
results_df <- data.frame(
  Method = c("Joint-RPCA", "Per-layer RPCA", "Single-layer RPCA", "Random"),
  Accuracy = c(res_joint$accuracy, res_rpca$accuracy, res_layer1$accuracy, res_random$accuracy),
  AUC = c(res_joint$auc, res_rpca$auc, res_layer1$auc, res_random$auc)
)

print(results_df)











# 1) Choose/derive labels (factor) --------------------------------------------
labels <- as.factor(colData(HintikkaXOData)$Diet)

# 2) Build a common sample index across all feature sets ----------------------
#    (joint scores and rclr tables share rownames)
rn_joint <- rownames(result$ord.res$samples)
rn_rclr  <- lapply(result$rclr.tables, rownames)
common_samples <- Reduce(intersect, lapply(result$rclr.tables, colnames))

# Helper: drop columns with 0 variance or all-NA/constant
drop_constant_cols <- function(X) {
  sds <- apply(X, 2, function(v) sd(v, na.rm = TRUE))
  keep <- is.finite(sds) & (sds > 0)
  if (!any(keep)) stop("No non-constant columns remain after filtering.")
  X[, keep, drop = FALSE]
}

# Drop columns that contain any NA/NaN/Inf
keep_finite_cols <- function(X) {
  ok <- apply(X, 2, function(v) all(is.finite(v)))
  if (!any(ok)) stop("All columns removed by finite filter.")
  X[, ok, drop = FALSE]
}

# Drop columns with zero variance (after finite filter)
drop_constant_cols <- function(X) {
  sds <- apply(X, 2, function(v) sd(v, na.rm = TRUE))
  keep <- is.finite(sds) & (sds > 0)
  if (!any(keep)) stop("No non-constant columns remain after filtering.")
  X[, keep, drop = FALSE]
}

# ---- Concatenated rCLR -> PCA (global PCA baseline) ----
X_list <- lapply(result$rclr.tables, function(tbl) t(tbl[, common_samples, drop = FALSE]))  # samples × features
features_rclr_concat <- do.call(cbind, X_list)

# 1) finite filter, 2) constant filter, THEN PCA
features_rclr_concat <- keep_finite_cols(features_rclr_concat)
features_rclr_concat <- drop_constant_cols(features_rclr_concat)

pca_concat <- prcomp(features_rclr_concat, center = TRUE, scale. = TRUE)
features_concat_pca <- pca_concat$x[, 1:10, drop = FALSE]

# ---- Per-layer PCA -> concatenate ----
K_pcs <- 3
dataset_specific_pca_scores <- lapply(result$rclr.tables, function(tbl) {
  X <- t(tbl[, common_samples, drop = FALSE])            # samples × features
  X <- keep_finite_cols(X)
  X <- drop_constant_cols(X)
  pca <- prcomp(X, center = TRUE, scale. = TRUE)
  k <- min(K_pcs, ncol(pca$x))
  pca$x[, seq_len(k), drop = FALSE]
})
features_pca_concat <- do.call(cbind, dataset_specific_pca_scores)

# ---- Per-layer RPCA -> concatenate (aligned) ----
dataset_specific_scores_aligned <- lapply(dataset_specific_scores, function(S) {
  S <- S[common_samples, , drop = FALSE]
  S <- keep_finite_cols(S)          # safe-guard
  drop_constant_cols(S)             # in case a component is constant on common samples
})
features_rpca_concat <- do.call(cbind, dataset_specific_scores_aligned)

# ---- Joint-RPCA shared scores (aligned) ----
features_jointRPCA <- result$ord.res$samples[common_samples, , drop = FALSE]
features_jointRPCA <- keep_finite_cols(features_jointRPCA)
features_jointRPCA <- drop_constant_cols(features_jointRPCA)

# ---- Random baseline ----
set.seed(1)
features_random <- matrix(rnorm(length(common_samples) * 10), nrow = length(common_samples), ncol = 10)
rownames(features_random) <- common_samples
colnames(features_random) <- paste0("rand_", seq_len(ncol(features_random)))

# ---- Align labels to the same sample order ----
labels <- droplevels(as.factor(colData(HintikkaXOData)$Diet)[common_samples])

stopifnot(
  nrow(features_jointRPCA) == length(labels),
  nrow(features_rpca_concat) == length(labels),
  nrow(features_pca_concat)  == length(labels),
  nrow(features_rclr_concat) == length(labels),
  nrow(features_random)      == length(labels)
)

# ========== Cross-validated evaluation helpers ==========
suppressPackageStartupMessages({
  library(caret)
  library(pROC)
  library(randomForest)
  library(dplyr)
  library(tidyr)
  library(ggplot2)
})

# Preprocess (center/scale) WITHOUT leakage: fit on train only, apply to test
prep_train_test <- function(X_train, X_test) {
  m <- colMeans(X_train, na.rm = TRUE)
  s <- apply(X_train, 2, sd, na.rm = TRUE)
  s[s == 0 | !is.finite(s)] <- 1
  list(
    Xtr = sweep(sweep(X_train, 2, m, "-"), 2, s, "/"),
    Xte = sweep(sweep(X_test,  2, m, "-"), 2, s, "/")
  )
}

# ---- Align labels to the same sample order ----
labels <- as.factor(colData(HintikkaXOData)$Diet)[common_samples]

# ---- Align labels to the same sample order ----
labels0 <- as.factor(colData(HintikkaXOData)$Diet)[common_samples]

# 1) drop NAs
keep_idx <- !is.na(labels0)

# 2) drop classes with < 2 samples
tab0 <- table(labels0[keep_idx])
keep_classes <- names(tab0)[tab0 >= 2]
keep_idx <- keep_idx & labels0 %in% keep_classes

# 3) sanity checks
if (!any(keep_idx)) stop("After filtering NAs and rare classes, no samples remain.")
labels <- droplevels(labels0[keep_idx])
if (nlevels(labels) < 2) stop("Need at least 2 classes after filtering.")
tab <- table(labels)

# 4) subset features to the safe set
features_jointRPCA <- features_jointRPCA[keep_idx, , drop = FALSE]
features_rpca_concat <- features_rpca_concat[keep_idx, , drop = FALSE]
features_pca_concat  <- features_pca_concat[keep_idx, , drop = FALSE]
features_concat_pca  <- features_concat_pca[keep_idx, , drop = FALSE]
features_random      <- features_random[keep_idx, , drop = FALSE]

# 5) choose a safe K for CV
safe_k <- max(2L, min(5L, as.integer(min(tab)), length(labels) - 1L))

evaluate_model_cv <- function(features, labels, folds = 5, ntree = 500, seed = 42) {
  set.seed(seed)

  # recompute safe k with current labels
  tab <- table(labels)
  if (length(labels) < 2L || length(tab) < 2L) stop("Need >=2 samples and >=2 classes.")
  folds <- max(2L, min(as.integer(folds), as.integer(min(tab)), length(labels) - 1L))

  folds_idx <- caret::createFolds(labels, k = folds, list = TRUE, returnTrain = FALSE)

  accs <- numeric(length(folds_idx))
  aucs <- numeric(length(folds_idx))

  for (i in seq_along(folds_idx)) {
    test_idx  <- folds_idx[[i]]
    train_idx <- setdiff(seq_along(labels), test_idx)

    Xtr <- features[train_idx, , drop = FALSE]
    Xte <- features[test_idx,  , drop = FALSE]
    ytr <- labels[train_idx]
    yte <- labels[test_idx]

    # skip degenerate train folds
    if (length(unique(ytr)) < 2L) { accs[i] <- NA_real_; aucs[i] <- NA_real_; next }

    pp <- prep_train_test(Xtr, Xte)
    rf <- randomForest::randomForest(x = pp$Xtr, y = ytr, ntree = ntree)

    yhat <- predict(rf, pp$Xte, type = "response")
    accs[i] <- mean(yhat == yte)

    probs <- predict(rf, pp$Xte, type = "prob")
    # ensure all class columns exist
    all_lvls <- levels(labels)
    miss <- setdiff(all_lvls, colnames(probs))
    if (length(miss)) for (mm in miss) probs <- cbind(probs, setNames(rep(0, nrow(probs)), mm))
    probs <- probs[, all_lvls, drop = FALSE]

    if (length(unique(yte)) < 2L) {
      aucs[i] <- NA_real_
    } else {
      aucs[i] <- tryCatch(as.numeric(pROC::multiclass.roc(yte, probs)$auc), error = function(e) NA_real_)
    }
  }

  list(accuracy = mean(accs, na.rm = TRUE), auc = mean(aucs, na.rm = TRUE))
}

# ========== Run all baselines ==========
res_joint   <- evaluate_model_cv(features_jointRPCA, labels, folds = safe_k)
res_rpca    <- evaluate_model_cv(features_rpca_concat, labels, folds = safe_k)
res_pca     <- evaluate_model_cv(features_pca_concat,  labels, folds = safe_k)
res_concat  <- evaluate_model_cv(features_concat_pca,  labels, folds = safe_k)
res_random  <- evaluate_model_cv(features_random,      labels, folds = safe_k)

results_df <- tibble::tibble(
  Method   = c("Joint‑RPCA (shared scores)",
               "Per‑layer RPCA → concat",
               "Per‑layer PCA → concat",
               "Concatenated rCLR → PCA",
               "Random"),
  Accuracy = c(res_joint$accuracy,
               res_rpca$accuracy,
               res_pca$accuracy,
               res_concat$accuracy,
               res_random$accuracy),
  MacroAUC = c(res_joint$auc,
               res_rpca$auc,
               res_pca$auc,
               res_concat$auc,
               res_random$auc)
) %>%
  arrange(desc(MacroAUC))

print(results_df)

# Quick visualization
results_long <- results_df |>
  tidyr::pivot_longer(cols = c(Accuracy, MacroAUC), names_to = "Metric", values_to = "Score")

ggplot(results_long, aes(x = reorder(Method, Score), y = Score)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~ Metric, scales = "free_x") +
  labs(x = NULL, y = "Score", title = "Classification benchmarks (5‑fold CV)") +
  theme_minimal(base_size = 12)
